# Tweet

Google DeepMind published a new paper on scaling test-time compute for LLMs. They found that letting models "think longer" via chain-of-thought at inference time can match the performance of a 14x larger model. Paper: arxiv.org/abs/2408.03314

## Expected
verdict: show
reason: factual tech news with source link
